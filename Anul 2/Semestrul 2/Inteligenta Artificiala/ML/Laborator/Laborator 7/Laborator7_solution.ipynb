{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23f25e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408d6f29",
   "metadata": {},
   "source": [
    "#### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d228e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_1=32, n_2=64, n_3=128, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Conv2d(3,n_1,3, padding=1)\n",
    "        self.maxpool_1 = nn.MaxPool2d(2)\n",
    "        self.conv_2 = nn.Conv2d(n_1,n_2,3, padding=1)\n",
    "        self.maxpool_2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_1 = nn.Linear(8*8*n_2, n_3)\n",
    "        self.classifier = nn.Linear(n_3, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.maxpool_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.maxpool_2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2afe7a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_dataloader = DataLoader(trainset, batch_size=64)\n",
    "test_dataloader = DataLoader(testset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc721de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_method(model, train_dataloader, optimizer, num_epochs=10, device=\"cpu\", loss_function=nn.CrossEntropyLoss()):\n",
    "    model.train(True)\n",
    "    for i in range(num_epochs):\n",
    "        for batch, (image_batch, labels_batch) in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            image_batch = image_batch.to(device)\n",
    "            labels_batch = labels_batch.to(device)\n",
    "\n",
    "            pred = model(image_batch)\n",
    "            loss = loss_function(pred, labels_batch)\n",
    "\n",
    "            # Backpropagation\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                    loss = loss.item()\n",
    "                    print(f\"Batch index {batch }, loss: {loss:>7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5195b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch index 0, loss: 2.305554\n",
      "Batch index 100, loss: 2.299860\n",
      "Batch index 200, loss: 2.287627\n",
      "Batch index 300, loss: 2.292756\n",
      "Batch index 400, loss: 2.251900\n",
      "Batch index 500, loss: 2.233685\n",
      "Batch index 600, loss: 2.228275\n",
      "Batch index 700, loss: 2.133688\n",
      "Batch index 0, loss: 2.123545\n",
      "Batch index 100, loss: 2.050705\n",
      "Batch index 200, loss: 1.865362\n",
      "Batch index 300, loss: 2.069502\n",
      "Batch index 400, loss: 1.995227\n",
      "Batch index 500, loss: 1.994694\n",
      "Batch index 600, loss: 2.033982\n",
      "Batch index 700, loss: 1.912492\n",
      "Batch index 0, loss: 1.947762\n",
      "Batch index 100, loss: 1.857972\n",
      "Batch index 200, loss: 1.621302\n",
      "Batch index 300, loss: 1.878610\n",
      "Batch index 400, loss: 1.841799\n",
      "Batch index 500, loss: 1.800498\n",
      "Batch index 600, loss: 1.874257\n",
      "Batch index 700, loss: 1.722835\n",
      "Batch index 0, loss: 1.883820\n",
      "Batch index 100, loss: 1.650578\n",
      "Batch index 200, loss: 1.493878\n",
      "Batch index 300, loss: 1.752527\n",
      "Batch index 400, loss: 1.613474\n",
      "Batch index 500, loss: 1.625133\n",
      "Batch index 600, loss: 1.736219\n",
      "Batch index 700, loss: 1.602712\n",
      "Batch index 0, loss: 1.800315\n",
      "Batch index 100, loss: 1.486146\n",
      "Batch index 200, loss: 1.391703\n",
      "Batch index 300, loss: 1.672842\n",
      "Batch index 400, loss: 1.436395\n",
      "Batch index 500, loss: 1.564900\n",
      "Batch index 600, loss: 1.596379\n",
      "Batch index 700, loss: 1.502436\n",
      "Batch index 0, loss: 1.636801\n",
      "Batch index 100, loss: 1.393685\n",
      "Batch index 200, loss: 1.290274\n",
      "Batch index 300, loss: 1.590087\n",
      "Batch index 400, loss: 1.315778\n",
      "Batch index 500, loss: 1.536218\n",
      "Batch index 600, loss: 1.489266\n",
      "Batch index 700, loss: 1.429029\n",
      "Batch index 0, loss: 1.575745\n",
      "Batch index 100, loss: 1.329347\n",
      "Batch index 200, loss: 1.217175\n",
      "Batch index 300, loss: 1.508655\n",
      "Batch index 400, loss: 1.225298\n",
      "Batch index 500, loss: 1.491140\n",
      "Batch index 600, loss: 1.403106\n",
      "Batch index 700, loss: 1.377344\n",
      "Batch index 0, loss: 1.474732\n",
      "Batch index 100, loss: 1.290770\n",
      "Batch index 200, loss: 1.143146\n",
      "Batch index 300, loss: 1.442536\n",
      "Batch index 400, loss: 1.160225\n",
      "Batch index 500, loss: 1.433364\n",
      "Batch index 600, loss: 1.328076\n",
      "Batch index 700, loss: 1.325296\n",
      "Batch index 0, loss: 1.395485\n",
      "Batch index 100, loss: 1.259592\n",
      "Batch index 200, loss: 1.076430\n",
      "Batch index 300, loss: 1.383466\n",
      "Batch index 400, loss: 1.110857\n",
      "Batch index 500, loss: 1.391130\n",
      "Batch index 600, loss: 1.260983\n",
      "Batch index 700, loss: 1.292982\n",
      "Batch index 0, loss: 1.308771\n",
      "Batch index 100, loss: 1.217798\n",
      "Batch index 200, loss: 1.018771\n",
      "Batch index 300, loss: 1.323838\n",
      "Batch index 400, loss: 1.065434\n",
      "Batch index 500, loss: 1.342117\n",
      "Batch index 600, loss: 1.204073\n",
      "Batch index 700, loss: 1.264475\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "                \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CNN()\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "train_method(model, train_dataloader,optimizer, device=device)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f40b422d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 52.5%, Loss: 0.020996 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_method(model, test_dataloader,loss_function=nn.CrossEntropyLoss()):\n",
    "    correct = 0.\n",
    "    test_loss = 0.\n",
    "    size = len(test_dataloader.dataset)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "            for image_batch, labels_batch in test_dataloader:\n",
    "\n",
    "                image_batch = image_batch.to(device)\n",
    "                labels_batch = labels_batch.to(device)\n",
    "                pred = model(image_batch)\n",
    "                test_loss += loss_function(pred, labels_batch).item()\n",
    "                correct += (pred.argmax(1) == labels_batch).type(torch.float).sum().item()\n",
    "\n",
    "\n",
    "    correct /= size\n",
    "    test_loss /= size\n",
    "    print(f\"Accuracy: {(100*correct):>0.1f}%, Loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "test_method(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d7ea75",
   "metadata": {},
   "source": [
    "#### Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b25665da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_BN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_1=32, n_2=64, n_3=128, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Conv2d(3,n_1,3, padding=1)\n",
    "        self.maxpool_1 = nn.MaxPool2d(2)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(n_1)\n",
    "        self.conv_2 = nn.Conv2d(n_1,n_2,3, padding=1)\n",
    "        self.maxpool_2 = nn.MaxPool2d(2)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(n_2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_1 = nn.Linear(8*8*n_2, n_3)\n",
    "        self.classifier = nn.Linear(n_3, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.maxpool_1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv_2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.maxpool_2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2a1fe83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch index 0, loss: 2.408558\n",
      "Batch index 100, loss: 1.519408\n",
      "Batch index 200, loss: 1.202026\n",
      "Batch index 300, loss: 1.237141\n",
      "Batch index 400, loss: 1.151495\n",
      "Batch index 500, loss: 1.340289\n",
      "Batch index 600, loss: 1.250158\n",
      "Batch index 700, loss: 1.267909\n",
      "Batch index 0, loss: 1.159328\n",
      "Batch index 100, loss: 0.979342\n",
      "Batch index 200, loss: 0.775441\n",
      "Batch index 300, loss: 0.854728\n",
      "Batch index 400, loss: 0.879415\n",
      "Batch index 500, loss: 1.004647\n",
      "Batch index 600, loss: 0.915058\n",
      "Batch index 700, loss: 1.141963\n",
      "Batch index 0, loss: 0.993686\n",
      "Batch index 100, loss: 0.811429\n",
      "Batch index 200, loss: 0.708854\n",
      "Batch index 300, loss: 0.730926\n",
      "Batch index 400, loss: 0.752022\n",
      "Batch index 500, loss: 0.807660\n",
      "Batch index 600, loss: 0.731036\n",
      "Batch index 700, loss: 0.970538\n",
      "Batch index 0, loss: 0.761122\n",
      "Batch index 100, loss: 0.684494\n",
      "Batch index 200, loss: 0.665581\n",
      "Batch index 300, loss: 0.661749\n",
      "Batch index 400, loss: 0.612149\n",
      "Batch index 500, loss: 0.700867\n",
      "Batch index 600, loss: 0.587089\n",
      "Batch index 700, loss: 0.799236\n",
      "Batch index 0, loss: 0.644873\n",
      "Batch index 100, loss: 0.534930\n",
      "Batch index 200, loss: 0.593978\n",
      "Batch index 300, loss: 0.606816\n",
      "Batch index 400, loss: 0.536199\n",
      "Batch index 500, loss: 0.637969\n",
      "Batch index 600, loss: 0.468401\n",
      "Batch index 700, loss: 0.694360\n",
      "Batch index 0, loss: 0.561974\n",
      "Batch index 100, loss: 0.462091\n",
      "Batch index 200, loss: 0.467499\n",
      "Batch index 300, loss: 0.508718\n",
      "Batch index 400, loss: 0.460803\n",
      "Batch index 500, loss: 0.528398\n",
      "Batch index 600, loss: 0.383793\n",
      "Batch index 700, loss: 0.562426\n",
      "Batch index 0, loss: 0.446440\n",
      "Batch index 100, loss: 0.352987\n",
      "Batch index 200, loss: 0.371090\n",
      "Batch index 300, loss: 0.406001\n",
      "Batch index 400, loss: 0.412912\n",
      "Batch index 500, loss: 0.464931\n",
      "Batch index 600, loss: 0.287958\n",
      "Batch index 700, loss: 0.455077\n",
      "Batch index 0, loss: 0.350807\n",
      "Batch index 100, loss: 0.280667\n",
      "Batch index 200, loss: 0.264561\n",
      "Batch index 300, loss: 0.315766\n",
      "Batch index 400, loss: 0.386901\n",
      "Batch index 500, loss: 0.370627\n",
      "Batch index 600, loss: 0.214459\n",
      "Batch index 700, loss: 0.363977\n",
      "Batch index 0, loss: 0.277437\n",
      "Batch index 100, loss: 0.222268\n",
      "Batch index 200, loss: 0.158216\n",
      "Batch index 300, loss: 0.242227\n",
      "Batch index 400, loss: 0.325327\n",
      "Batch index 500, loss: 0.273371\n",
      "Batch index 600, loss: 0.168706\n",
      "Batch index 700, loss: 0.239579\n",
      "Batch index 0, loss: 0.194394\n",
      "Batch index 100, loss: 0.176776\n",
      "Batch index 200, loss: 0.115703\n",
      "Batch index 300, loss: 0.145069\n",
      "Batch index 400, loss: 0.242605\n",
      "Batch index 500, loss: 0.211511\n",
      "Batch index 600, loss: 0.130466\n",
      "Batch index 700, loss: 0.157410\n"
     ]
    }
   ],
   "source": [
    "model = CNN_BN()\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "train_method(model, train_dataloader,optimizer, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d78d0341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.2%, Loss: 0.019341 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_method(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf15047",
   "metadata": {},
   "source": [
    "#### Exercise 3 - TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df0567f",
   "metadata": {},
   "source": [
    "#### Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a88aeb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_in = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.identity_downsample is not None:\n",
    "            x_in = self.identity_downsample(x_in)\n",
    "        x += x_in\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a68be21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_18(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_channels, num_classes):\n",
    "        \n",
    "        super(ResNet_18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=3, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self.__make_layer(64, 64, stride=1)\n",
    "        self.layer2 = self.__make_layer(64, 128, stride=2)\n",
    "        self.layer3 = self.__make_layer(128, 256, stride=2)\n",
    "        self.layer4 = self.__make_layer(256, 512, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def __make_layer(self, in_channels, out_channels, stride):\n",
    "        \n",
    "        identity_downsample = None\n",
    "        if stride != 1:\n",
    "            identity_downsample = self.identity_downsample(in_channels, out_channels)\n",
    "            \n",
    "        return nn.Sequential(\n",
    "            Block(in_channels, out_channels, identity_downsample=identity_downsample, stride=stride), \n",
    "            Block(out_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x \n",
    "    \n",
    "    def identity_downsample(self, in_channels, out_channels):\n",
    "        \n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04bae444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch index 0, loss: 2.283956\n",
      "Batch index 100, loss: 1.490906\n",
      "Batch index 200, loss: 1.352313\n",
      "Batch index 300, loss: 1.229783\n",
      "Batch index 400, loss: 1.206150\n",
      "Batch index 500, loss: 1.421167\n",
      "Batch index 600, loss: 1.028060\n",
      "Batch index 700, loss: 1.148655\n",
      "Batch index 0, loss: 1.068752\n",
      "Batch index 100, loss: 1.086675\n",
      "Batch index 200, loss: 0.859755\n",
      "Batch index 300, loss: 0.954995\n",
      "Batch index 400, loss: 1.009810\n",
      "Batch index 500, loss: 1.031324\n",
      "Batch index 600, loss: 0.736846\n",
      "Batch index 700, loss: 0.900311\n",
      "Batch index 0, loss: 0.789972\n",
      "Batch index 100, loss: 0.838167\n",
      "Batch index 200, loss: 0.696882\n",
      "Batch index 300, loss: 0.695152\n",
      "Batch index 400, loss: 0.795864\n",
      "Batch index 500, loss: 0.904908\n",
      "Batch index 600, loss: 0.644490\n",
      "Batch index 700, loss: 0.780502\n",
      "Batch index 0, loss: 0.704047\n",
      "Batch index 100, loss: 0.713931\n",
      "Batch index 200, loss: 0.581069\n",
      "Batch index 300, loss: 0.642847\n",
      "Batch index 400, loss: 0.648851\n",
      "Batch index 500, loss: 0.798788\n",
      "Batch index 600, loss: 0.487425\n",
      "Batch index 700, loss: 0.620114\n",
      "Batch index 0, loss: 0.629633\n",
      "Batch index 100, loss: 0.556148\n",
      "Batch index 200, loss: 0.378974\n",
      "Batch index 300, loss: 0.545315\n",
      "Batch index 400, loss: 0.378523\n",
      "Batch index 500, loss: 0.588740\n",
      "Batch index 600, loss: 0.501805\n",
      "Batch index 700, loss: 0.410998\n",
      "Batch index 0, loss: 0.463972\n",
      "Batch index 100, loss: 0.427255\n",
      "Batch index 200, loss: 0.289792\n",
      "Batch index 300, loss: 0.580215\n",
      "Batch index 400, loss: 0.251254\n",
      "Batch index 500, loss: 0.543560\n",
      "Batch index 600, loss: 0.304002\n",
      "Batch index 700, loss: 0.258254\n",
      "Batch index 0, loss: 0.302928\n",
      "Batch index 100, loss: 0.242357\n",
      "Batch index 200, loss: 0.242590\n",
      "Batch index 300, loss: 0.402509\n",
      "Batch index 400, loss: 0.264772\n",
      "Batch index 500, loss: 0.444010\n",
      "Batch index 600, loss: 0.247034\n",
      "Batch index 700, loss: 0.146729\n",
      "Batch index 0, loss: 0.296958\n",
      "Batch index 100, loss: 0.327605\n",
      "Batch index 200, loss: 0.159588\n",
      "Batch index 300, loss: 0.377746\n",
      "Batch index 400, loss: 0.265325\n",
      "Batch index 500, loss: 0.212422\n",
      "Batch index 600, loss: 0.115314\n",
      "Batch index 700, loss: 0.183439\n",
      "Batch index 0, loss: 0.175304\n",
      "Batch index 100, loss: 0.233395\n",
      "Batch index 200, loss: 0.153964\n",
      "Batch index 300, loss: 0.177896\n",
      "Batch index 400, loss: 0.220568\n",
      "Batch index 500, loss: 0.134515\n",
      "Batch index 600, loss: 0.194646\n",
      "Batch index 700, loss: 0.222859\n",
      "Batch index 0, loss: 0.120539\n",
      "Batch index 100, loss: 0.092037\n",
      "Batch index 200, loss: 0.063120\n",
      "Batch index 300, loss: 0.072099\n",
      "Batch index 400, loss: 0.152525\n",
      "Batch index 500, loss: 0.191126\n",
      "Batch index 600, loss: 0.260357\n",
      "Batch index 700, loss: 0.295995\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = ResNet_18(3, 10)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "train_method(model, train_dataloader,optimizer, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bb8a6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.4%, Loss: 0.023139 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_method(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f926f91",
   "metadata": {},
   "source": [
    "#### Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1376153a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch index 0, loss: 2.318187\n",
      "Batch index 100, loss: 1.554341\n",
      "Batch index 200, loss: 1.194525\n",
      "Batch index 300, loss: 1.300476\n",
      "Batch index 400, loss: 1.179474\n",
      "Batch index 500, loss: 1.399907\n",
      "Batch index 600, loss: 1.272939\n",
      "Batch index 700, loss: 1.261730\n",
      "Batch index 0, loss: 1.228448\n",
      "Batch index 100, loss: 1.044472\n",
      "Batch index 200, loss: 0.893021\n",
      "Batch index 300, loss: 1.024370\n",
      "Batch index 400, loss: 0.864569\n",
      "Batch index 500, loss: 1.174369\n",
      "Batch index 600, loss: 0.968998\n",
      "Batch index 700, loss: 1.073501\n",
      "Batch index 0, loss: 1.071552\n",
      "Batch index 100, loss: 0.804586\n",
      "Batch index 200, loss: 0.809968\n",
      "Batch index 300, loss: 0.872152\n",
      "Batch index 400, loss: 0.709867\n",
      "Batch index 500, loss: 0.987279\n",
      "Batch index 600, loss: 0.797487\n",
      "Batch index 700, loss: 0.907548\n",
      "Batch index 0, loss: 0.917729\n",
      "Batch index 100, loss: 0.647796\n",
      "Batch index 200, loss: 0.737414\n",
      "Batch index 300, loss: 0.783761\n",
      "Batch index 400, loss: 0.601010\n",
      "Batch index 500, loss: 0.849717\n",
      "Batch index 600, loss: 0.661306\n",
      "Batch index 700, loss: 0.765580\n",
      "Batch index 0, loss: 0.762485\n",
      "Batch index 100, loss: 0.539589\n",
      "Batch index 200, loss: 0.624365\n",
      "Batch index 300, loss: 0.650425\n",
      "Batch index 400, loss: 0.495935\n",
      "Batch index 500, loss: 0.741090\n",
      "Batch index 600, loss: 0.571321\n",
      "Batch index 700, loss: 0.666756\n",
      "Batch index 0, loss: 0.671105\n",
      "Batch index 100, loss: 0.459494\n",
      "Batch index 200, loss: 0.527144\n",
      "Batch index 300, loss: 0.536862\n",
      "Batch index 400, loss: 0.404204\n",
      "Batch index 500, loss: 0.604835\n",
      "Batch index 600, loss: 0.478091\n",
      "Batch index 700, loss: 0.590175\n",
      "Batch index 0, loss: 0.545635\n",
      "Batch index 100, loss: 0.400406\n",
      "Batch index 200, loss: 0.416799\n",
      "Batch index 300, loss: 0.422855\n",
      "Batch index 400, loss: 0.332506\n",
      "Batch index 500, loss: 0.509107\n",
      "Batch index 600, loss: 0.388648\n",
      "Batch index 700, loss: 0.494724\n",
      "Batch index 0, loss: 0.409160\n",
      "Batch index 100, loss: 0.346737\n",
      "Batch index 200, loss: 0.333785\n",
      "Batch index 300, loss: 0.269030\n",
      "Batch index 400, loss: 0.288392\n",
      "Batch index 500, loss: 0.405663\n",
      "Batch index 600, loss: 0.303355\n",
      "Batch index 700, loss: 0.381389\n",
      "Batch index 0, loss: 0.305669\n",
      "Batch index 100, loss: 0.312175\n",
      "Batch index 200, loss: 0.265892\n",
      "Batch index 300, loss: 0.179668\n",
      "Batch index 400, loss: 0.219291\n",
      "Batch index 500, loss: 0.332715\n",
      "Batch index 600, loss: 0.210585\n",
      "Batch index 700, loss: 0.330590\n",
      "Batch index 0, loss: 0.235529\n",
      "Batch index 100, loss: 0.274101\n",
      "Batch index 200, loss: 0.160808\n",
      "Batch index 300, loss: 0.125879\n",
      "Batch index 400, loss: 0.190756\n",
      "Batch index 500, loss: 0.253038\n",
      "Batch index 600, loss: 0.166075\n",
      "Batch index 700, loss: 0.232981\n",
      "Accuracy: 68.2%, Loss: 0.019398 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy(prediction, target):\n",
    "    if len(target.shape)<2:\n",
    "        target = F.one_hot(target,num_classes=10)\n",
    "        \n",
    "    prediction = F.softmax(prediction, dim=1)\n",
    "    loss = torch.mean(-torch.sum(target*torch.log(prediction), dim=1))\n",
    "    return loss\n",
    "\n",
    "\n",
    "model = CNN_BN()\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "train_method(model, train_dataloader,optimizer, device=device,loss_function=cross_entropy)\n",
    "test_method(model, test_dataloader, loss_function=cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a45f042",
   "metadata": {},
   "source": [
    "#### Exercise 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c7eda9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_BN_2(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_1=32, n_2=64, n_3=128, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Conv2d(3,n_1,3, padding=1)\n",
    "        self.maxpool_1 = nn.MaxPool2d(2)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(n_1)\n",
    "        self.conv_2 = nn.Conv2d(n_1,n_2,3, padding=1)\n",
    "        self.maxpool_2 = nn.MaxPool2d(2)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(n_2)\n",
    "        \n",
    "        self.conv_3 = nn.Conv2d(n_2,10,3, padding=1)\n",
    "        self.maxpool_3 = nn.AdaptiveMaxPool2d(1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.maxpool_1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv_2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.maxpool_2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv_3(x)\n",
    "        x = self.maxpool_3(x)\n",
    "        x = self.flatten(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cfdb582d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch index 0, loss: 2.379418\n",
      "Batch index 100, loss: 1.755855\n",
      "Batch index 200, loss: 1.647958\n",
      "Batch index 300, loss: 1.660318\n",
      "Batch index 400, loss: 1.786109\n",
      "Batch index 500, loss: 1.760313\n",
      "Batch index 600, loss: 1.570919\n",
      "Batch index 700, loss: 1.557300\n",
      "Batch index 0, loss: 1.726953\n",
      "Batch index 100, loss: 1.436235\n",
      "Batch index 200, loss: 1.324642\n",
      "Batch index 300, loss: 1.433405\n",
      "Batch index 400, loss: 1.336527\n",
      "Batch index 500, loss: 1.531586\n",
      "Batch index 600, loss: 1.424391\n",
      "Batch index 700, loss: 1.330997\n",
      "Batch index 0, loss: 1.623825\n",
      "Batch index 100, loss: 1.203476\n",
      "Batch index 200, loss: 1.137386\n",
      "Batch index 300, loss: 1.360807\n",
      "Batch index 400, loss: 1.228426\n",
      "Batch index 500, loss: 1.407627\n",
      "Batch index 600, loss: 1.368546\n",
      "Batch index 700, loss: 1.284905\n",
      "Batch index 0, loss: 1.346929\n",
      "Batch index 100, loss: 1.154137\n",
      "Batch index 200, loss: 0.967894\n",
      "Batch index 300, loss: 1.194200\n",
      "Batch index 400, loss: 1.173339\n",
      "Batch index 500, loss: 1.391725\n",
      "Batch index 600, loss: 1.242189\n",
      "Batch index 700, loss: 1.208147\n",
      "Batch index 0, loss: 1.279605\n",
      "Batch index 100, loss: 1.152522\n",
      "Batch index 200, loss: 0.893895\n",
      "Batch index 300, loss: 1.144944\n",
      "Batch index 400, loss: 1.161463\n",
      "Batch index 500, loss: 1.392121\n",
      "Batch index 600, loss: 1.197086\n",
      "Batch index 700, loss: 1.126509\n",
      "Batch index 0, loss: 1.288782\n",
      "Batch index 100, loss: 1.137413\n",
      "Batch index 200, loss: 0.921368\n",
      "Batch index 300, loss: 1.105564\n",
      "Batch index 400, loss: 1.167449\n",
      "Batch index 500, loss: 1.286606\n",
      "Batch index 600, loss: 1.212809\n",
      "Batch index 700, loss: 1.098981\n",
      "Batch index 0, loss: 1.234688\n",
      "Batch index 100, loss: 1.138186\n",
      "Batch index 200, loss: 0.893097\n",
      "Batch index 300, loss: 1.022712\n",
      "Batch index 400, loss: 1.083408\n",
      "Batch index 500, loss: 1.320957\n",
      "Batch index 600, loss: 1.152617\n",
      "Batch index 700, loss: 1.063239\n",
      "Batch index 0, loss: 1.218445\n",
      "Batch index 100, loss: 1.088452\n",
      "Batch index 200, loss: 0.837723\n",
      "Batch index 300, loss: 1.017336\n",
      "Batch index 400, loss: 1.031934\n",
      "Batch index 500, loss: 1.265844\n",
      "Batch index 600, loss: 1.127058\n",
      "Batch index 700, loss: 1.033249\n",
      "Batch index 0, loss: 1.193827\n",
      "Batch index 100, loss: 1.077809\n",
      "Batch index 200, loss: 0.809645\n",
      "Batch index 300, loss: 1.020800\n",
      "Batch index 400, loss: 1.023024\n",
      "Batch index 500, loss: 1.267188\n",
      "Batch index 600, loss: 1.062428\n",
      "Batch index 700, loss: 1.054615\n",
      "Batch index 0, loss: 1.216983\n",
      "Batch index 100, loss: 1.074520\n",
      "Batch index 200, loss: 0.821438\n",
      "Batch index 300, loss: 1.031775\n",
      "Batch index 400, loss: 0.981002\n",
      "Batch index 500, loss: 1.267431\n",
      "Batch index 600, loss: 1.058220\n",
      "Batch index 700, loss: 1.018311\n",
      "Accuracy: 56.3%, Loss: 0.020091 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = CNN_BN_2()\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "train_method(model, train_dataloader,optimizer, device=device,loss_function=cross_entropy)\n",
    "test_method(model, test_dataloader, loss_function=cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d73af5",
   "metadata": {},
   "source": [
    "#### Exercise 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "604af9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 3, 3])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x1300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 8, 3, 3])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import utils\n",
    "import numpy as np\n",
    "\n",
    "def visualize_tensor(tensor, no_filters=8, nrow=8): \n",
    "    tensor = tensor[:,:no_filters,:,:]\n",
    "    n,c,w,h = tensor.shape\n",
    "    print(tensor.shape)\n",
    "    tensor = tensor.reshape(n*c, -1, w, h)\n",
    "\n",
    "    rows = np.min((tensor.shape[0] // nrow + 1, 64))    \n",
    "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=1)\n",
    "    plt.figure(figsize=(nrow,rows) )\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "    \n",
    "\n",
    "layers = list(model.parameters())\n",
    "fil = layers[0].data.to('cpu')\n",
    "visualize_tensor(fil)\n",
    "plt.axis('off')\n",
    "plt.ioff()\n",
    "plt.show()\n",
    "\n",
    "fil = layers[-2].data.to('cpu')\n",
    "visualize_tensor(fil)\n",
    "plt.axis('off')\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "101cc10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 64, 3, 3])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[-2].data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
