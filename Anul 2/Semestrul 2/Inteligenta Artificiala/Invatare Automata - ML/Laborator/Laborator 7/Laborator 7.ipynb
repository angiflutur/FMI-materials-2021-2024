{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bfc888f",
   "metadata": {},
   "source": [
    "### Convolutional neural networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965f5cc3",
   "metadata": {},
   "source": [
    "Operatia de convolutie in cazul 2D discret:\n",
    "\n",
    "![2D_Convolution_Animation.gif](./2D_Convolution_Animation.gif)\n",
    "\n",
    "Image source: https://en.wikipedia.org/wiki/Convolution#/media/File:2D_Convolution_Animation.gif\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86303f4",
   "metadata": {},
   "source": [
    "### Definirea stratului convolutional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2631626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da078697",
   "metadata": {},
   "source": [
    "Tensorul asociat stratului convolutional anterior:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb7a122",
   "metadata": {},
   "source": [
    "![tensor_conv.png](./tensor_conv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30100fd5",
   "metadata": {},
   "source": [
    "### Definirea stratului de pooling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0026c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.MaxPool2d(kernel_size, stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4883c5a6",
   "metadata": {},
   "source": [
    "![maxpool_example.png](./maxpool_example.png)\n",
    "\n",
    "Image source: https://paperswithcode.com/method/max-pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2176a77",
   "metadata": {},
   "source": [
    "### Proprietati stratul convolutional\n",
    "\n",
    "1. **parameter sharing**\n",
    "\n",
    "Intr-o retea fully connected (MLP) un parametrul al acesteia este folosit o singura data in procesarea unui exemplu, pe cand in CNN un parametru ( o pozitie dintr-un filtru) este folosit pentru fiecare pozitie a tensorului de intrare (daca stride-ul este 1).\n",
    "\n",
    "2. **local connectivity**\n",
    "\n",
    "In CNNs o valoare din mapa de activare rezulta din aplicarea filtrului pe o zona locala, pe cand in MLP fiecare neuron este conectat cu intreg semnalul de intrare.\n",
    "\n",
    "3. **equivariance to translation**\n",
    "\n",
    "Un filtru va produce acelasi nivel de activare pentru un pattern in semnal, indiferent de locul unde pattern-ul respectiv se afla.\n",
    "\n",
    "### Proprietati stratul de pooling\n",
    "\n",
    "1. **Invarianta la mici translatii** datorata sumarizarii cu o statistica a zonelor din semnal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8a7cb9",
   "metadata": {},
   "source": [
    "### O retea convolutionala:\n",
    "\n",
    "![cnn.png](./cnn.png)\n",
    "\n",
    "Image source: https://paperswithcode.com/methods/category/convolutional-neural-networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f137afc",
   "metadata": {},
   "source": [
    "In imaginea de mai sus se foloseste **Flatten** pentru a transforma tensorul din forma 3D intr-unul 1 dimensional. O alta varianta este sa aplicam pooling + squeeze pe dimensiunile spatiale. In Pytorch putem implementa asta cu **nn.AdaptiveMaxPool2d**:\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool2d.html#torch.nn.AdaptiveMaxPool2d\n",
    "\n",
    "\n",
    "**Exemplu:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a992a4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dupa operatia de pooling:torch.Size([5, 64, 1, 1])\n",
      "Shape dupa squeeze:torch.Size([5, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "pooling = nn.AdaptiveMaxPool2d((1, 1))\n",
    "result = pooling(torch.rand(5, 64, 4, 4))\n",
    "print(f\"Shape dupa operatia de pooling:{result.shape}\")\n",
    "print(f\"Shape dupa squeeze:{torch.squeeze(result).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e153ae",
   "metadata": {},
   "source": [
    "#### 3. Exercitii\n",
    "\n",
    "1. Creati reteaua din imaginea de mai sus, dar cu dimensiunea filtrelor (kernel size) setata la 3.  Antrenati si testati performanta retelei pe setul de date **CIFAR10**.\n",
    "\n",
    "a) folositi $n1=32$, $n2=64$ si $n3=128$ si adaugati activarea ReLU dupa straturile convolutionale.\n",
    "\n",
    "b) folositi $n1=64$, $n2=128$ si $n3=256$ si adaugati activarea ReLU dupa straturile convolutionale.\n",
    "\n",
    "c) aceeasi configuratie ca la punctul b), dar setati kernel size la 5 pentru primul strat.\n",
    "\n",
    "`\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=ToTensor())\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=ToTensor())\n",
    "`\n",
    "\n",
    "2. Introduceti straturi BatchNorm2D in reteaua de la exercitiul precedent. Testati din nou performanta pe setul de date CIFAR10. Ce observati?\n",
    "Documentatie: https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html\n",
    "\n",
    "\n",
    "3. Inlocuiti **Flatten** in reteaua de la exercitiul anterior cu max pooling ca in exemplul de mai sus.\n",
    "\n",
    "\n",
    "4.In acest exercitiu vom implementa **ResNet-18**.\n",
    "\n",
    "a) Creati o clasa care sa implementeze stack-ul de straturi descris in imaginea urmatoare. Numarul de canale in imagine este 64, in implementarea voastra faceti-l configurabil. Observati operatia de adunare efectuata intre tensorul de intrare si iesire din bloc (poarta numele de skip/residual connection).\n",
    "\n",
    "![res_block.png](./res_block.png)\n",
    "\n",
    "b) Folosindu-va de bloc-ul de straturi implementat la punctul anterior, implementati arhitectura din imaginea urmatoare. In cazul nostru imaginile nu sunt de rezolutie (100, 100), de aceea setam kernel size in primul strat la 3, in loc de 7 cum este in imagine.\n",
    "\n",
    "\n",
    "![resnet18-architecture.png](./resnet18-architecture.png)\n",
    "\n",
    "5. Implementati propria functie echivalenta cu cross entropia.\n",
    "\n",
    "`def cross_entropy(prediction, target)`\n",
    "\n",
    "\n",
    "6. Modificati reteaua de la exercitiul 2 astfel incat sa renuntati la straturile fully connected de la final si sa le inlocuiti cu straturi de pooling si straturi convolutionale.\n",
    "\n",
    "\n",
    "7. Creati o vizualizare pentru filtrele din primul si ultimul strat convolutional (pentru primele 8 canale).\n",
    "Folositi metoda parameters() a modelului pentru a accesa straturile.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f56a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
